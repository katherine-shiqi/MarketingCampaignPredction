{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Import Data and Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "from tabulate import tabulate\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (7414, 22)\n",
      "testing data shape: (824, 22)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"marketing_training.csv\")\n",
    "df_test = pd.read_csv(\"marketing_test.csv\")\n",
    "print('training data shape:', df_train.shape)\n",
    "print('testing data shape:', df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define a function to replace the categorical variable with dummy variables (one-hot encoding)\n",
    "# e.g column 'gender' = female --> column 'female' = 1 \n",
    "def Category2Dummy(df, feature):\n",
    "    dummy = pd.get_dummies(df[feature])\n",
    "    dummy.columns = [feature + '_' +str(x) for x in dummy.columns]\n",
    "    dummy.drop(dummy.columns[len(dummy.columns)-1], axis=1, inplace=True)\n",
    "    df = pd.concat([df, dummy], axis=1)\n",
    "    return df\n",
    "\n",
    "def Category2Numeric(x, Map):\n",
    "    if x in Map:\n",
    "        return Map[x]\n",
    "    \n",
    "def Numeric2Category(x,Map):\n",
    "    for i, item in Map.items():\n",
    "        if x==item:\n",
    "            return(i)\n",
    "\n",
    "# impute the missing values: (dataframe, model, columns for imputation, target column with missing values)\n",
    "def Impute(df, model, column, target):\n",
    "    for i, row in df[df[target].isnull()].iterrows():\n",
    "        df.ix[i, target] = model.predict(row[column].reshape(1, -1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing\n",
    "###    *Missing Value Imputation\n",
    "###    *Categorical into Dummy Variables\n",
    "###    *Handle the imbalance Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "custAge           1804\n",
       "profession           0\n",
       "marital              0\n",
       "schooling         2155\n",
       "default              0\n",
       "housing              0\n",
       "loan                 0\n",
       "contact              0\n",
       "month                0\n",
       "day_of_week        711\n",
       "campaign             0\n",
       "pdays                0\n",
       "previous             0\n",
       "poutcome             0\n",
       "emp.var.rate         0\n",
       "cons.price.idx       0\n",
       "cons.conf.idx        0\n",
       "euribor3m            0\n",
       "nr.employed          0\n",
       "pmonths              0\n",
       "pastEmail            0\n",
       "responded            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum() # missing values: 'custAge','profession','marital'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Typically three ways to deal with missing value. Here I implemented the first method, since it can better capture the correlation between variables.\n",
    "    1.Imputation with prediction method (tree-based method, KNN, Logistic Regression, etc.)\n",
    "    2.Imputation with mean/mode \n",
    "    3.Removing the missing rows "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we need to transform categorical variables into dummy variables to predict missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Transform categorical into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "categorylist = df_train.dtypes[df_train.dtypes.values=='O'].index.tolist() # get categorical column names\n",
    "categorylist.remove('schooling') #remove columns needed to be predicted (missing values)\n",
    "categorylist.remove('day_of_week')\n",
    "categorylist.remove('responded') #remove y column - deal with this later\n",
    "# ['profession', 'marital', 'default', 'housing', 'loan', 'contact', 'month', 'poutcome']\n",
    "\n",
    "for item in categorylist: # change them into dummy columns\n",
    "    df_train = Category2Dummy(df_train,item) \n",
    "df_train = df_train.drop(categorylist, axis = 1) # remove original categorical columns\n",
    "\n",
    "# To predict missing values based on columns in the imputationlist \n",
    "imputationlist = [x for x in df_train.columns if (x != 'custAge') and (x != 'responded') and (x != 'schooling') and (x != 'day_of_week')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 'custAge' imputation --Linear Regression for continuous variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative mean square error =  -66.8542760912\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "train = df_train[~df_train['custAge'].isnull()]\n",
    "score = np.mean(cross_val_score(lr, train[imputationlist], train['custAge'], cv=6, scoring = 'neg_mean_squared_error'))\n",
    "print('negative mean square error = ', score) # cross validation to calculate the score\n",
    "lr.fit(train[imputationlist], train['custAge']) # use imputation columns to predict the 'custAge' column\n",
    "df_train = Impute(df_train, lr, imputationlist, 'custAge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 'schooling' imputation --Logistic Regression for categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Turn categorical into numerical variables\n",
    "Map_schooling,i = {},0\n",
    "for item in df_train['schooling'].value_counts().index:\n",
    "    Map_schooling[item] = i\n",
    "    i += 1\n",
    "\n",
    "df_train['schooling'] = df_train['schooling'].apply(lambda x: Category2Numeric(x,Map_schooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.49060222463\n"
     ]
    }
   ],
   "source": [
    "lg = LogisticRegression()\n",
    "train = df_train[~df_train['schooling'].isnull()]\n",
    "score = np.mean(cross_val_score(lg, train[imputationlist], train['schooling'], cv=6, scoring = 'accuracy'))\n",
    "print('accuracy = ', score)\n",
    "lg = LogisticRegression().fit(train[imputationlist], train['schooling'])\n",
    "df_train = Impute(df_train, lg, imputationlist, 'schooling')\n",
    "\n",
    "# Turn numerical variables back to categorical variables\n",
    "df_train['schooling'] = df_train['schooling'].apply(lambda x: Numeric2Category(x,Map_schooling))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 'day_of_week' imputation --Random Forest for categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Turn categorical into numerical variables\n",
    "Map_day,i = {},0\n",
    "for item in df_train['day_of_week'].value_counts().index:\n",
    "    Map_day[item] = i\n",
    "    i += 1\n",
    "\n",
    "df_train['day_of_week'] = df_train['day_of_week'].apply(lambda x: Category2Numeric(x,Map_day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.527075927632\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "train = df_train[~df_train['day_of_week'].isnull()]\n",
    "score = np.mean(cross_val_score(rf, train[imputationlist], train['day_of_week'], cv=6, scoring = 'accuracy'))\n",
    "print('accuracy = ', score)\n",
    "rf.fit(train[imputationlist], train['day_of_week'])\n",
    "df_train = Impute(df_train, rf, imputationlist, 'day_of_week')\n",
    "# Turn numerical variables back to categorical variables\n",
    "df_train['day_of_week'] = df_train['day_of_week'].apply(lambda x: Numeric2Category(x,Map_day))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 Save imputation models and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the imputation models for testing data preprocessing\n",
    "with open(\"custAge.pkl\", \"wb\") as fid:\n",
    "    pickle.dump(lr, fid)\n",
    "    fid.close()\n",
    "with open(\"schooling.pkl\", \"wb\") as fid:\n",
    "    pickle.dump(lg, fid)\n",
    "    fid.close()\n",
    "with open(\"day_of_week.pkl\", \"wb\") as fid:\n",
    "    pickle.dump(rf, fid)\n",
    "    fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.6 Transform the remaining categorical and target variables into dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert into dummy variables\n",
    "remain_categorylist = ['schooling', 'day_of_week']\n",
    "for item in remain_categorylist:\n",
    "    df_train = Category2Dummy(df_train, item)\n",
    "df_train = df_train.drop(remain_categorylist, axis = 1)\n",
    "\n",
    "# Convert target variable into binary variable\n",
    "# no => 0, yes => 1\n",
    "df_train.ix[df_train.responded == 'no', 'responded'] = 0\n",
    "df_train.ix[df_train.responded == 'yes', 'responded'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.7 Handle the imbalance problem (SMOTE+AUC matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6574\n",
      "1     840\n",
      "Name: responded, dtype: int64\n",
      "# of responed= 6574\n",
      "# of non-responed= 6574\n"
     ]
    }
   ],
   "source": [
    "print(df_train.responded.value_counts()) \n",
    "# our dataset has serious imbalance problem, non-responded/responded = 7.83\n",
    "# Solution: 1. Over/Under Sampling- SMOTE 2.AUC matrix which is insensitive to imbalance\n",
    "train_x = df_train.ix[:, df_train.columns != 'responded']\n",
    "train_y = df_train['responded'].tolist()\n",
    "sm = SMOTE(random_state=12, ratio = 1.0) # set it to 1:1\n",
    "train_x_sm, train_y_sm = sm.fit_sample(train_x, train_y)\n",
    "print ('# of responed=',np.bincount(train_y_sm.astype(int))[0])\n",
    "print ('# of non-responed=',np.bincount(train_y_sm.astype(int))[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save important features for testing data preprocessing\n",
    "predictors = [x for x in df_train.columns if x != 'responded']\n",
    "FeatureDict = {'categorylist': categorylist, 'imputationlist': imputationlist,'predictors':predictors , 'Map_schooling': Map_schooling, 'Map_day': Map_day}\n",
    "with open('FeatureDict.json', 'w') as f:\n",
    "    json.dump(FeatureDict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Compare several algorithms\n",
    "#Logistic Regression, Random Forest, Support Vector Machine(Linear and Non-Linear), gradient boosting\n",
    "lg = LogisticRegression()\n",
    "rf = RandomForestClassifier()\n",
    "svc = LinearSVC()\n",
    "svcRad = SVC()\n",
    "gb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tune hyper parameters based on the AUC matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Random Forest  [n_estimators=238]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best n_estimators =  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=238, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "Estimators = np.linspace(10, 300, 20)\n",
    "Estimators = [int(item) for item in Estimators]\n",
    "rf_est = GridSearchCV(rf, {'n_estimators': Estimators}, scoring = 'roc_auc')\n",
    "rf_est.fit(train_x_sm, train_y_sm)\n",
    "print('best n_estimators = ', rf_est.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) Linear SVM  [C=0.01], SVM with rbf kernel [C=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVM, C =  LinearSVC(C=0.01, class_weight=None, dual=True, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0)\n",
      "SVM with rbf kernel, C = SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "1\n",
    "svc_c = GridSearchCV(svc, {'C': Estimators}, scoring = 'roc_auc')\n",
    "svcRad_c = GridSearchCV(svcRad, {'C': Estimators}, scoring = 'roc_auc')\n",
    "svc_c.fit(train_x_sm, train_y_sm)\n",
    "svcRad_c.fit(train_x_sm, train_y_sm)\n",
    "print ('Linear SVM, C = ', svc_c.best_estimator_)\n",
    "print ('SVM with rbf kernel, C =', svcRad_c.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) Gradient Boosting [n_estimators=80, learning rate=0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best n_estimators, learning rate =  GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.20000000000000001, loss='deviance',\n",
      "              max_depth=3, max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=80, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "Estimators = np.linspace(10, 200, 20)\n",
    "Estimators = [int(item) for item in Estimators]\n",
    "LearningRate = np.linspace(0.1, 1, 10)\n",
    "gb_best = GridSearchCV(gb, {'n_estimators': Estimators, 'learning_rate': LearningRate}, scoring = 'roc_auc')\n",
    "gb_best.fit(train_x_sm, train_y_sm)\n",
    "print('best n_estimators, learning rate = ', gb_best.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Model Comparison \n",
    "    Select a model with the highest AUC by running K fold cross validation (K=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Logistic Regression, Random Forest, Support Vector Machine(Linear and Non-Linear), gradient boosting\n",
    "lg = LogisticRegression()\n",
    "rf = RandomForestClassifier(n_estimators = 238)\n",
    "svc = LinearSVC(C = 0.01)\n",
    "svcRad = SVC(C = 100)\n",
    "gb = GradientBoostingClassifier(n_estimators=80 ,learning_rate= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression average AUC =  0.819198898225\n",
      "Random Forest average AUC =  0.987625310959\n",
      "Linear SVM average AUC =  0.780516023885\n",
      "SVM with RBF kernel average AUC =  0.976134548457\n",
      "Gradient Boosting average AUC =  0.972325787384\n"
     ]
    }
   ],
   "source": [
    "# model selection \n",
    "lgScore = cross_val_score(lg, train_x_sm, train_y_sm, cv=6, scoring = 'roc_auc')\n",
    "rfScore = cross_val_score(rf, train_x_sm, train_y_sm, cv=6, scoring = 'roc_auc')\n",
    "svcScore = cross_val_score(svc, train_x_sm, train_y_sm, cv=6, scoring = 'roc_auc')\n",
    "svcRadScore = cross_val_score(svcRad, train_x_sm, train_y_sm, cv=6, scoring = 'roc_auc')\n",
    "gbScore = cross_val_score(gb, train_x_sm, train_y_sm, cv=6, scoring = 'roc_auc')\n",
    "\n",
    "print('Logistic Regression average AUC = ', np.mean(lgScore))\n",
    "print('Random Forest average AUC = ', np.mean(rfScore))\n",
    "print('Linear SVM average AUC = ', np.mean(svcScore))\n",
    "print('SVM with RBF kernel average AUC = ', np.mean(svcRadScore))\n",
    "print('Gradient Boosting average AUC = ', np.mean(gbScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Model: Random Forest with AUC = 0.9876"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Final Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build our final model and save is as pickle file for predicting testing dataset \n",
    "rf = RandomForestClassifier(n_estimators = 238)\n",
    "rf.fit(train_x_sm, train_y_sm)\n",
    "\n",
    "with open('Final_Model.pkl','wb') as fid:\n",
    "    pickle.dump(rf, fid)\n",
    "    fid.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                             score\n",
      "euribor3m                    0.0949023\n",
      "nr.employed                  0.0588953\n",
      "housing_no                   0.0536977\n",
      "custAge                      0.0497186\n",
      "emp.var.rate                 0.0486179\n",
      "contact_cellular             0.0377063\n",
      "campaign                     0.0359795\n",
      "day_of_week_mon              0.0352473\n",
      "schooling_university.degree  0.0342015\n",
      "profession_admin.            0.0323301\n",
      "day_of_week_fri              0.0280962\n",
      "profession_blue-collar       0.0279946\n",
      "schooling_high.school        0.0247216\n",
      "cons.conf.idx                0.0240825\n",
      "day_of_week_tue              0.0228869\n"
     ]
    }
   ],
   "source": [
    "headers = [\"name\", \"score\"]\n",
    "values = sorted(zip(predictors, rf.feature_importances_), key=lambda x: x[1] * -1)\n",
    "values = values[0:15] #top 15\n",
    "print(tabulate(values, headers, tablefmt=\"plain\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAGLCAYAAADAhflWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYxqGDb8xxjQMG35jjGkYNvzGGNMw/j8GqKJyJiyF6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d305a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Figure - Feature Importance Top 15\")\n",
    "plt.bar(np.linspace(1, len(values), len(values)), [x[1] for x in values], color=\"b\")\n",
    "plt.xticks(np.linspace(1, len(values), len(values)), [x[0] for x in values], rotation='vertical')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Make Prediction for Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                  0\n",
       "custAge           210\n",
       "profession          0\n",
       "marital             0\n",
       "schooling         251\n",
       "default             0\n",
       "housing             0\n",
       "loan                0\n",
       "contact             0\n",
       "month               0\n",
       "day_of_week        76\n",
       "campaign            0\n",
       "pdays               0\n",
       "previous            0\n",
       "poutcome            0\n",
       "emp.var.rate        0\n",
       "cons.price.idx      0\n",
       "cons.conf.idx       0\n",
       "euribor3m           0\n",
       "nr.employed         0\n",
       "pmonths             0\n",
       "pastEmail           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"marketing_test.csv\")\n",
    "df_test=df_test.rename(columns = {df_test.columns[0]:'id'})\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (1) open imputation model and feature dictionary saved in section 1.5 and 1.7\n",
    "with open(\"custAge.pkl\", \"rb\") as f:\n",
    "    AgeModel = pickle.load(f)\n",
    "with open(\"schooling.pkl\", \"rb\") as f:\n",
    "    SchoolModel = pickle.load(f)\n",
    "with open(\"day_of_week.pkl\", \"rb\") as f:\n",
    "    DayModel = pickle.load(f)\n",
    "with open('FeatureDict.json', 'r') as f: \n",
    "    List = json.load(f)\n",
    "    predictors = List['predictors'] # predictors of final model\n",
    "    categorylist = List['categorylist'] # categorical columns needed to be transformed into dummy\n",
    "    imputationlist =List['imputationlist'] # columns for predicting missing values in those columns\n",
    "    Map_schooling = List['Map_schooling'] # Dictionary to map value to index. For predicting missing values\n",
    "    Map_day = List['Map_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (2) change categorical columns into dummy columns\n",
    "for item in categorylist: \n",
    "    df_test = Category2Dummy(df_test,item) \n",
    "df_test = df_test.drop(categorylist, axis = 1) # remove original categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (3) missing values imputation\n",
    "\n",
    "# columns in the training set not in the testing set. set them as 0\n",
    "imputationlist2 = [x for x in df_test.columns if (x != 'custAge') and (x != 'responded') and (x != 'schooling') and (x != 'day_of_week')]\n",
    "for column in set(imputationlist) - set(imputationlist2):\n",
    "    df_test[column] = 0\n",
    "    \n",
    "# map category to numeric\n",
    "df_test['day_of_week'] = df_test['day_of_week'].apply(lambda x: Category2Numeric(x, Map_day))\n",
    "df_test['schooling'] = df_test['schooling'].apply(lambda x: Category2Numeric(x, Map_schooling))\n",
    "\n",
    "# predict\n",
    "df_test = Impute(df_test, AgeModel, imputationlist, 'custAge')\n",
    "df_test = Impute(df_test, SchoolModel, imputationlist, 'schooling')\n",
    "df_test = Impute(df_test, DayModel, imputationlist, 'day_of_week')\n",
    "\n",
    "# map numeric to categorical\n",
    "df_test['day_of_week'] = df_test['day_of_week'].apply(lambda x: Numeric2Category(x,Map_day))\n",
    "df_test['schooling'] = df_test['schooling'].apply(lambda x: Numeric2Category(x,Map_schooling))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (4) convert remaining categorical columns into dummy columns\n",
    "remain_categorylist = ['schooling', 'day_of_week']\n",
    "for item in remain_categorylist:\n",
    "    df_test = Category2Dummy(df_test, item)\n",
    "df_test = df_test.drop(remain_categorylist, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 data prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "with open('Final_Model.pkl','rb') as f:\n",
    "        finalmodel = pickle.load(f)      \n",
    "\n",
    "# if columns in training set not in testing, set values as 0\n",
    "predictors1 = df_test.columns.tolist()[1:] # testing dataset columns\n",
    "for column in set(predictors) - set(predictors1):\n",
    "    df_test[column]=0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>responded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>794</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>798</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>799</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>801</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>803</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>804</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>806</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>808</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>809</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>810</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>811</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>813</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>814</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>815</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>816</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>822</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>823</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  responded\n",
       "0      0          0\n",
       "1      1          0\n",
       "2      2          0\n",
       "3      3          0\n",
       "4      4          0\n",
       "5      5          0\n",
       "6      6          0\n",
       "7      7          0\n",
       "8      8          1\n",
       "9      9          0\n",
       "10    10          0\n",
       "11    11          0\n",
       "12    12          0\n",
       "13    13          0\n",
       "14    14          0\n",
       "15    15          0\n",
       "16    16          0\n",
       "17    17          0\n",
       "18    18          0\n",
       "19    19          0\n",
       "20    20          0\n",
       "21    21          0\n",
       "22    22          0\n",
       "23    23          0\n",
       "24    24          0\n",
       "25    25          0\n",
       "26    26          0\n",
       "27    27          0\n",
       "28    28          0\n",
       "29    29          1\n",
       "..   ...        ...\n",
       "794  794          0\n",
       "795  795          0\n",
       "796  796          0\n",
       "797  797          0\n",
       "798  798          0\n",
       "799  799          0\n",
       "800  800          0\n",
       "801  801          0\n",
       "802  802          0\n",
       "803  803          1\n",
       "804  804          0\n",
       "805  805          0\n",
       "806  806          0\n",
       "807  807          0\n",
       "808  808          0\n",
       "809  809          0\n",
       "810  810          0\n",
       "811  811          0\n",
       "812  812          0\n",
       "813  813          0\n",
       "814  814          0\n",
       "815  815          0\n",
       "816  816          0\n",
       "817  817          0\n",
       "818  818          0\n",
       "819  819          0\n",
       "820  820          0\n",
       "821  821          0\n",
       "822  822          0\n",
       "823  823          0\n",
       "\n",
       "[824 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make prediction and save the model \n",
    "df_test['responded'] = finalmodel.predict(df_test[predictors])\n",
    "df_test[['id','responded']].to_csv(\"test_prediction.csv\")\n",
    "df_test[['id','responded']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    779\n",
       "1     45\n",
       "Name: responded, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.responded.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
